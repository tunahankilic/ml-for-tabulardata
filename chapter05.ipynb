{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./AB_NYC_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "excluding_list = [\n",
    "    'price', 'id', 'latitude', \n",
    "    'longitude', 'host_id', \n",
    "    'last_review', 'name',\n",
    "    'host_name'\n",
    "    ]\n",
    "\n",
    "categorical = [\n",
    "    'neighbourhood_group',\n",
    "    'neighbourhood',\n",
    "    'room_type'\n",
    "    ]\n",
    "\n",
    "continuous = [\n",
    "    'minimum_nights',\n",
    "    'number_of_reviews',\n",
    "    'reviews_per_month',\n",
    "    'calculated_host_listings_count',\n",
    "    'availability_365'\n",
    "    ] \n",
    "\n",
    "\n",
    "low_card_categorical = [\n",
    "    'neighbourhood_group',\n",
    "    'room_type'\n",
    "]\n",
    "\n",
    "high_card_categorical = [\n",
    "    'neighbourhood',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mean = (data[\"price\"] > data[\"price\"].mean()).astype(int)\n",
    "target_median = (data[\"price\"] > data[\"price\"].median()).astype(int)\n",
    "target_multiclass = pd.qcut(data[\"price\"], q=5, labels=False)\n",
    "target_regression = data[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_onehot = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "numeric_passthrough = SimpleImputer(strategy='constant', fill_value=0)\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('hugh_card_categories', categorical_ordinal, high_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.965 | Test: 0.761 (0.005) | fit: 0.14 secs pred: 0.01 secs\n"
     ]
    }
   ],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")\n",
    "\n",
    "model = DecisionTreeClassifier(random_state=0)\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])    \n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])   \n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging and Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.965 | Test: 0.809 (0.004) | fit: 26.01 secs pred: 0.56 secs\n"
     ]
    }
   ],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")\n",
    "\n",
    "model = BaggingClassifier(\n",
    "    estimator=DecisionTreeClassifier(),\n",
    "    n_estimators=300,\n",
    "    bootstrap=True,\n",
    "    max_samples=1.0,\n",
    "    max_features=1.0,\n",
    "    random_state=0\n",
    ")\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])    \n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])   \n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.883 | Test: 0.826 (0.004) | fit: 10.17 secs pred: 0.48 secs\n"
     ]
    }
   ],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=0\n",
    ")\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])    \n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])   \n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.828 | Test: 0.823 (0.004) | fit: 2.84 secs pred: 0.23 secs\n"
     ]
    }
   ],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    n_estimators=300,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=0\n",
    ")\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])    \n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])   \n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientBoosting():\n",
    "    def __init__(self, n_estimators=100, learning_rate=0.1, **params):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.learning_rate = learning_rate\n",
    "        self.params = params\n",
    "        self.trees = list()\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        x = np.clip(x, -100, 100)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def logit(self, x, eps=1e-6):\n",
    "        xp = np.clip(x, eps, 1-eps)\n",
    "        return np.log(xp / (1 - xp))\n",
    "    \n",
    "    def gradient(self, y, y_pred):\n",
    "        gradient = y_pred - y\n",
    "        return gradient\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.init = self.logit(np.mean(y))\n",
    "        y_pred = self.init * np.ones((X.shape[0], ))\n",
    "        for k in range(self.n_estimators):\n",
    "            gradient = self.gradient(self.logit(y), y_pred)\n",
    "            tree = DecisionTreeRegressor(**self.params)\n",
    "            tree.fit(X, -gradient)\n",
    "            self.trees.append(tree)\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        y_pred = self.init * np.ones((X.shape[0], ))\n",
    "        for tree in self.trees:\n",
    "            y_pred += self.learning_rate * tree.predict(X)\n",
    "        return self.sigmoid(y_pred)\n",
    "    \n",
    "    def predict(self, X, threshold=0.5):\n",
    "        proba = self.predict_proba(X)\n",
    "        return np.where(proba >= threshold, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_onehot = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "numeric_passthrough = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Classifier Accuracy: 0.82493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(range(len(data)), test_size=0.2, random_state=0)\n",
    "\n",
    "cls = GradientBoosting(n_estimators=300, learning_rate=0.1, min_samples_leaf=3, max_depth=4)\n",
    "X = column_transform.fit_transform(data.iloc[train])\n",
    "y = target_median[train]\n",
    "\n",
    "cls.fit(X, y)\n",
    "Xt = column_transform.transform(data.iloc[test])\n",
    "yt = target_median[test]\n",
    "ypred = cls.predict(Xt)\n",
    "score = accuracy_score(yt, ypred)\n",
    "print(f\"Gradient Boosting Classifier Accuracy: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting in SkLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_onehot = OneHotEncoder(handle_unknown='ignore')\n",
    "categorical_ordinal = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=np.nan)\n",
    "numeric_passthrough = SimpleImputer(strategy='constant', fill_value=0)\n",
    "\n",
    "column_transform = ColumnTransformer(\n",
    "    [\n",
    "        ('low_card_categories', categorical_onehot, low_card_categorical),\n",
    "        ('numeric', numeric_passthrough, continuous)\n",
    "    ],\n",
    "    remainder='drop', # Dropping any remaining unprocessed columns\n",
    "    verbose_feature_names_out=False,\n",
    "    sparse_threshold=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.839 | Test: 0.826 (0.004) | fit: 8.38 secs pred: 0.04 secs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.833 | Test: 0.826 (0.005) | fit: 7.87 secs pred: 0.05 secs\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.1,\n",
    "    validation_fraction=0.2,\n",
    "    n_iter_no_change=10,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=3,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', model)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[145, 109, 115, 163, 159]\n"
     ]
    }
   ],
   "source": [
    "iters = [cv_scores[\"estimator\"][i].named_steps[\"model\"].n_estimators_ for i in range(5)] \n",
    "print(iters) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations to use in full training: 166\n"
     ]
    }
   ],
   "source": [
    "np.mean(iters)\n",
    "print(f\"Number of iterations to use in full training: {1.2 * np.mean(iters):.0f}\") # Increase the number of iterations by 20% since it is a validation fraction in CV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.849 | Test: 0.826 (0.004) | fit: 0.27 secs pred: 0.02 secs\n"
     ]
    }
   ],
   "source": [
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "xgb = XGBClassifier(\n",
    "    booster='gbtree',\n",
    "    objective='reg:logistic',\n",
    "    n_estimators=300,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3, # equivalent to min_samples_leaf of SKLearn\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', xgb)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping in XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Classifier Accuracy: 0.82657\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    range(len(data)),\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "train, valid = train_test_split(\n",
    "    train,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "xgb = XGBClassifier(\n",
    "    booster='gbtree',\n",
    "    objective='reg:logistic',\n",
    "    n_estimators=1000,\n",
    "    max_depth=4,\n",
    "    min_child_weight=3, # equivalent to min_samples_leaf of SKLearn\n",
    "    early_stopping_rounds=100,\n",
    "    eval_metric='error',\n",
    ")\n",
    "\n",
    "X = column_transform.fit_transform(data.iloc[train])\n",
    "y = target_median[train]\n",
    "Xv = column_transform.transform(data.iloc[valid])\n",
    "yv = target_median[valid]\n",
    "\n",
    "xgb.fit(X, y, eval_set=[(Xv, yv)], verbose=False)\n",
    "\n",
    "Xt = column_transform.transform(data.iloc[test])\n",
    "yt = target_median[test]\n",
    "\n",
    "preds = xgb.predict(Xt)\n",
    "score = accuracy_score(yt, preds)\n",
    "print(f\"XGBoost Classifier Accuracy: {score:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.best_iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>host_id</th>\n",
       "      <th>host_name</th>\n",
       "      <th>neighbourhood_group</th>\n",
       "      <th>neighbourhood</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>room_type</th>\n",
       "      <th>price</th>\n",
       "      <th>minimum_nights</th>\n",
       "      <th>number_of_reviews</th>\n",
       "      <th>last_review</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>availability_365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539</td>\n",
       "      <td>Clean &amp; quiet apt home by the park</td>\n",
       "      <td>2787</td>\n",
       "      <td>John</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Kensington</td>\n",
       "      <td>40.64749</td>\n",
       "      <td>-73.97237</td>\n",
       "      <td>Private room</td>\n",
       "      <td>149</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>0.21</td>\n",
       "      <td>6</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2595</td>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>2845</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Midtown</td>\n",
       "      <td>40.75362</td>\n",
       "      <td>-73.98377</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>225</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>2019-05-21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>2</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3647</td>\n",
       "      <td>THE VILLAGE OF HARLEM....NEW YORK !</td>\n",
       "      <td>4632</td>\n",
       "      <td>Elisabeth</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Harlem</td>\n",
       "      <td>40.80902</td>\n",
       "      <td>-73.94190</td>\n",
       "      <td>Private room</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3831</td>\n",
       "      <td>Cozy Entire Floor of Brownstone</td>\n",
       "      <td>4869</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>Brooklyn</td>\n",
       "      <td>Clinton Hill</td>\n",
       "      <td>40.68514</td>\n",
       "      <td>-73.95976</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>89</td>\n",
       "      <td>1</td>\n",
       "      <td>270</td>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>4.64</td>\n",
       "      <td>1</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5022</td>\n",
       "      <td>Entire Apt: Spacious Studio/Loft by central park</td>\n",
       "      <td>7192</td>\n",
       "      <td>Laura</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>East Harlem</td>\n",
       "      <td>40.79851</td>\n",
       "      <td>-73.94399</td>\n",
       "      <td>Entire home/apt</td>\n",
       "      <td>80</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-11-19</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                              name  host_id  \\\n",
       "0  2539                Clean & quiet apt home by the park     2787   \n",
       "1  2595                             Skylit Midtown Castle     2845   \n",
       "2  3647               THE VILLAGE OF HARLEM....NEW YORK !     4632   \n",
       "3  3831                   Cozy Entire Floor of Brownstone     4869   \n",
       "4  5022  Entire Apt: Spacious Studio/Loft by central park     7192   \n",
       "\n",
       "     host_name neighbourhood_group neighbourhood  latitude  longitude  \\\n",
       "0         John            Brooklyn    Kensington  40.64749  -73.97237   \n",
       "1     Jennifer           Manhattan       Midtown  40.75362  -73.98377   \n",
       "2    Elisabeth           Manhattan        Harlem  40.80902  -73.94190   \n",
       "3  LisaRoxanne            Brooklyn  Clinton Hill  40.68514  -73.95976   \n",
       "4        Laura           Manhattan   East Harlem  40.79851  -73.94399   \n",
       "\n",
       "         room_type  price  minimum_nights  number_of_reviews last_review  \\\n",
       "0     Private room    149               1                  9  2018-10-19   \n",
       "1  Entire home/apt    225               1                 45  2019-05-21   \n",
       "2     Private room    150               3                  0         NaN   \n",
       "3  Entire home/apt     89               1                270  2019-07-05   \n",
       "4  Entire home/apt     80              10                  9  2018-11-19   \n",
       "\n",
       "   reviews_per_month  calculated_host_listings_count  availability_365  \n",
       "0               0.21                               6               365  \n",
       "1               0.38                               2               355  \n",
       "2                NaN                               1               365  \n",
       "3               4.64                               1               194  \n",
       "4               0.10                               1                 0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.859 | Test: 0.826 (0.004) | fit: 0.62 secs pred: 0.04 secs\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "accuracy = make_scorer(accuracy_score)\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "lgb = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    n_estimators=300,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=3,\n",
    "    force_col_wise=True,\n",
    "    verbosity=0,\n",
    ")\n",
    "\n",
    "model_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('processing', column_transform),\n",
    "        ('model', lgb)\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_validate(\n",
    "    estimator=model_pipeline,\n",
    "    X=data,\n",
    "    y=target_median,\n",
    "    scoring=accuracy,\n",
    "    cv=cv,\n",
    "    return_train_score=True,\n",
    "    return_estimator=True,\n",
    ")\n",
    "\n",
    "train_cv = np.mean(cv_scores['train_score'])\n",
    "mean_cv = np.mean(cv_scores['test_score'])\n",
    "std_cv = np.std(cv_scores['test_score'])\n",
    "fit_time = np.mean(cv_scores['fit_time'])\n",
    "score_time = np.mean(cv_scores['score_time'])\n",
    "print(f\"Train: {train_cv:.3f} |\",\n",
    "      f\"Test: {mean_cv:0.3f} ({std_cv:0.3f}) |\", \n",
    "      f\"fit: {fit_time:0.2f}\", f\"secs pred: {score_time:0.2f} secs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import log_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Classifier Accuracy: 0.82585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tunahan.kilic\\OneDrive - ERIKS\\Desktop\\Developer\\ml-for-tabulardata\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(\n",
    "    range(len(data)),\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "train, valid = train_test_split(\n",
    "    train,\n",
    "    test_size=0.2,\n",
    "    random_state=0\n",
    ")\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    boosting_type='gbdt',\n",
    "    early_stopping_round=150,\n",
    "    n_estimators=1000,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=3, # equivalent to min_samples_leaf of SKLearn\n",
    "    force_col_wise=True,\n",
    "    verbosity=0,\n",
    ")\n",
    "X = column_transform.fit_transform(data.iloc[train])\n",
    "y = target_median[train]\n",
    "Xv = column_transform.transform(data.iloc[valid])\n",
    "yv = target_median[valid]\n",
    "\n",
    "lgbm.fit(\n",
    "    X, y, eval_set=[(Xv, yv)],\n",
    "    eval_metric='accuracy',\n",
    "    callbacks=[log_evaluation(0)]\n",
    ")\n",
    "\n",
    "Xt = column_transform.transform(data.iloc[test])\n",
    "yt = target_median[test]\n",
    "preds = lgbm.predict(Xt)\n",
    "score = accuracy_score(yt, preds)   \n",
    "print(f\"LightGBM Classifier Accuracy: {score:.5f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
